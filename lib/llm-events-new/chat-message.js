/*
 * Copyright 2026 New Relic Corporation. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 */

const LlmEvent = require('./base')

/**
 * An event that corresponds to each message (sent and received)
 * from a chat completion call including those created by the user,
 * assistant, and the system.
 *
 * @property {string} id ID in the format `response_id`-`sequence`,
 *  or a UUID generated by the agent if no response ID is returned by the LLM
 */
class LlmChatCompletionMessage extends LlmEvent {
  /**
   *
   * @param {object} params constructor params
   * @param {Agent} params.agent New Relic agent instance
   * @param {object} params.segment Current segment
   * @param {object} params.transaction Current and active transaction
   * @param {string} params.vendor Lowercase name of vendor (e.g. 'openai')
   * @param {string} params.requestId ID associated with the request -
   *    typically available in response headers
   * @param {string} params.responseId ID associated with the response
   * @param {string} params.responseModel Model name returned in the response
   * @param {number} params.sequence Index (beginning at 0) associated with
   *    each message including the prompt and responses
   * @param {string} params.content Content of the message
   * @param {string} [params.role] Role of the message creator (e.g. `user`, `assistant`, `tool`)
   * @param {string} params.completionId ID of the `LlmChatCompletionSummary` event that
   *    this message event is connected to
   * @param {boolean} [params.isResponse] `true` if a message is the result of a chat
   *    completion and not an input message - omitted in `false` cases
   */
  constructor({ agent, segment, transaction, vendor, requestId, responseId, responseModel, sequence, content, role, completionId, isResponse }) {
    super({ agent, segment, transaction, vendor, responseModel, requestId })

    this.completion_id = completionId
    this.sequence = sequence
    if (isResponse) this.is_response = isResponse

    if (role) {
      this.role = role
    } else {
      // If the role attribute is not available, a value of user MUST be sent for
      // requests and a value of assistant MUST be sent for responses.
      if (isResponse) {
        this.role = 'assistant'
      } else if (sequence === 0) {
        // We can assume the first message in the sequence is the request message.
        this.role = 'user'
      }
    }

    if (isResponse !== true) {
      // Only include for input/request messages
      this.timestamp = segment.timer.start
    }

    if (responseId) {
      // A UUID is generated for `id` in super constructor,
      // but use this id format if responseId exists
      this.id = `${responseId}-${sequence}`
    }

    if (agent.config.ai_monitoring.record_content.enabled === true) {
      this.content = content
    }
  }
}

module.exports = LlmChatCompletionMessage
